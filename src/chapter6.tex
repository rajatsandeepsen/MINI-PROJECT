\chapter{Experimental Results}


This project consist of two things. First, a custom LLM to LAM convertor with Action model engine which is open sourced by us on github. Second an example banking application we build on top of these open source Action model concept. 

By doing so, we aimed to revolutionize the entire function calling process, freeing developers from the burden of tedious manual function calling AI and empowering them to focus on more valuable tasks in building core features of application.This Action model concept is a wrapper over LLM, which can be a pioneering step towards comprehensive AI agents inside softwares.

\section{System Description}

Our system uses default microphone API to accept voice as input. This obtained input is then processed to normal text string using the default \textbf{voice-to-text} API. These string values are then given to the preprocessor to accurately parse convert it to instructions to LLM and the LLM predict what to do with this informations. The result from this step is forwarded to Action Model Engine to further check the integrity and execute the functions sequentially.

\section{Existing Solutions}

\noindent
Since there is some journal that focus on single type function calling. But these systems can't invoke multiple function in sequential because return of previous functions are input of next function. So recently these primitive system can support multiple action agents with multiple LLM invoke. But our system support the multiple sequential function calling with single LLM request. We discuss the literature review in detail by exploring how each research paper contributed to the creation of our system.

\noindent
When we initially formed our idea, we wanted the idea to be projected in a way that helps developer build their own action model on top of open source LLMs. Our initial sources understanding action models are from Rabbit R1 (a device that supports teachable AI assistant that can use other applications like human), but since they are closed-source software, we could not rely on them to understand how the backend of their applications works.

\noindent A python package named kor gave us the inspiration to build the drop-in-replacement to TypeScript language. It work efficiently to teach LLM to respond in strict JSON format. Combined with zod and LangChain to build the system. Packages like LangChain or AI-SDK from NPM already supports simple function calling, which is not enough to build full fledged Action Model Agents.

\section{Summary}

\noindent 
Initially, the aim was to develop a package that helps developer build their own action model on top of open source LLMs. Tool that ensures a seamless and efficient user experience with the application or software. Eventually offering developers and software business owners a better user experience feedback. With the integration of LLM and LAM (Large Action Model) technologies, this applications not only enhances the speed and efficiency of extracting data but also paves the way for Automated function calling tools.

\noindent
Additionally, a NPM package for the system was developed using the TypeScript. Published and developers can install it as extension to their LangChain projects. But still this Project has more room for improvements.
